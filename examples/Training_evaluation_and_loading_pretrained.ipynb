{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b16b418-d4a5-4534-ae38-fae8891f638e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook aims to give a slightly more comprehensive introduction into training, and evaluating the model on the example of the 3D cluster data. This will cover training a local and EFA augmented model, as well as collecting test metrics from an hold out test data set. We also show how one can load and use the pre-trained model from the checkpoints in `../pretrained`. \n",
    "\n",
    "Other models, e.g. for cumulene, SN2, dimers and so on, can be trained in a similar fashion, by simply replacing the `NpzTrainer` and the `EnergyModel` with the correct hyperparameters. This is done in a per-dataset fashion in the `models` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44c212-7a40-44f5-9deb-ca9ad3033724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import numpy as np\n",
    "import e3x\n",
    "import pathlib\n",
    "import wandb\n",
    "\n",
    "from euclidean_fast_attention import EnergyModel\n",
    "from euclidean_fast_attention import NpzTrainer\n",
    "\n",
    "import orbax.checkpoint as ocp\n",
    "import pathlib\n",
    "\n",
    "def load_params(ckpt_dir):\n",
    "    loaded_mngr = ocp.CheckpointManager(\n",
    "        pathlib.Path(ckpt_dir).expanduser().absolute().resolve(),\n",
    "        item_names=('params', ),\n",
    "        item_handlers={\n",
    "            'params': ocp.StandardCheckpointHandler(),\n",
    "        },\n",
    "        options=ocp.CheckpointManagerOptions(step_prefix=\"ckpt\"),\n",
    "    )\n",
    "    restored = loaded_mngr.restore(\n",
    "        loaded_mngr.latest_step(),\n",
    "        args=None\n",
    "    )\n",
    "\n",
    "    return restored['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b739a2f-9421-4a63-98ea-4d0c745f60bc",
   "metadata": {},
   "source": [
    "# Train the model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68299f-3267-4c2d-be3e-4a67f55707e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by setting the hyper parameters\n",
    "\n",
    "num_iterations = 2\n",
    "batch_size = 32\n",
    "use_efa = True\n",
    "\n",
    "# Number of atoms in cluster either 16 or 32\n",
    "num_atoms = 32\n",
    "\n",
    "if num_atoms == 32:\n",
    "    radius_string = '5'\n",
    "elif num_atoms == 16:\n",
    "    radius_string = '2point5'\n",
    "else:\n",
    "    raise ValueError('Only 3D cluster data sets for N=16 and N=32 exist.')\n",
    "\n",
    "if use_efa is True:\n",
    "    efa_handle = 'with_efa'\n",
    "else:\n",
    "    efa_handle = 'no_efa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65649bd4-8088-4f8e-a214-102fce1f6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = False\n",
    "\n",
    "if use_wandb is True:\n",
    "    # If wandb is used we must initialize the run\n",
    "    wandb.init(\n",
    "        project='euclidean_fast_attention', \n",
    "        group='3d_cluster', \n",
    "        name=f'efa_{num_atoms=}_radius_{radius_string}_{num_iterations=}_{batch_size=}'\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    log_interval_steps = 10_000\n",
    "\n",
    "ckpt_dir = pathlib.Path(\n",
    "    f'3d_cluster_{num_atoms=}_radius_{radius_string}_{num_iterations=}_{batch_size=}_{efa_handle}'\n",
    ").resolve().expanduser()\n",
    "\n",
    "npztrainer = NpzTrainer(\n",
    "    data_dir=data_path,\n",
    "    num_train=1500,\n",
    "    num_valid=500,\n",
    "    num_epochs=5000,\n",
    "    max_num_nodes=int(batch_size * num_atoms + 1),\n",
    "    max_num_edges=int(batch_size * num_atoms * min(num_atoms, 40) + 1),\n",
    "    max_num_graphs=batch_size + 1,\n",
    "    energy_unit=1,\n",
    "    length_unit=1,\n",
    "    log_interval_steps=log_interval_steps,\n",
    "    save_interval_steps=2000,\n",
    "    use_wandb=use_wandb\n",
    ")\n",
    "\n",
    "if use_efa is True:\n",
    "    model = EnergyModel(\n",
    "        num_features=128,\n",
    "        mp_max_degree=1,\n",
    "        num_iterations=num_iterations,\n",
    "        era_use_in_iterations=[0, 1],\n",
    "        era_lebedev_num=50,\n",
    "        era_tensor_integration=False,\n",
    "        era_include_pseudotensors=False,\n",
    "        era_max_degree=0,\n",
    "        era_qk_num_features=16,\n",
    "        era_v_num_features=32,\n",
    "        era_max_frequency=jnp.pi,\n",
    "        era_max_length=15,\n",
    "        era_activation_fn=e3x.nn.gelu,\n",
    "    )\n",
    "else:\n",
    "    model = EnergyModel(\n",
    "        num_features=128,\n",
    "        mp_max_degree=1,\n",
    "        num_iterations=num_iterations,\n",
    "        era_use_in_iterations=None\n",
    "        )\n",
    "\n",
    "schedule = optax.exponential_decay(\n",
    "    init_value=1e-3,\n",
    "    transition_steps=int(\n",
    "        npztrainer.num_train\n",
    "        / (npztrainer.max_num_graphs - 1)\n",
    "        * npztrainer.num_epochs\n",
    "    ),\n",
    "    decay_rate=1e-5 / 1e-3,\n",
    ")\n",
    "\n",
    "optimizer = optax.adam(learning_rate=schedule)\n",
    "\n",
    "_ = npztrainer.run_training(model, optimizer, ckpt_dir=ckpt_dir)\n",
    "\n",
    "params = load_params(ckpt_dir)\n",
    "\n",
    "# After training, the model can be evluated as\n",
    "metrics = npztrainer.run_testing(\n",
    "    params=params, \n",
    "    model=model, \n",
    "    num_test=500, \n",
    "    collect_predictions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c959b-8b64-42b5-ad7a-927a0e3d4412",
   "metadata": {},
   "source": [
    "# Load the Model From Checkpoint\n",
    "\n",
    "Alternatively, one can load the model parameters from the pre-trained checkpoints. For example, execute the code below for \n",
    "`use_efa = True` and `use_efa = False` to replicate the points in Fig. 3B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a754b-62a1-4995-a1af-e00c8828fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by setting the hyper parameters\n",
    "\n",
    "num_iterations = 2\n",
    "batch_size = 32\n",
    "use_efa = False\n",
    "\n",
    "# Number of atoms in cluster either 16 or 32\n",
    "num_atoms = 32\n",
    "\n",
    "if num_atoms == 32:\n",
    "    radius_string = '5'\n",
    "elif num_atoms == 16:\n",
    "    radius_string = '2point5'\n",
    "else:\n",
    "    raise ValueError('Only 3D cluster data sets for N=16 and N=32 exist.')\n",
    "\n",
    "if use_efa is True:\n",
    "    efa_handle = 'with_efa'\n",
    "else:\n",
    "    efa_handle = 'without_efa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebfff3-e705-47c4-aa7b-3484c1a050dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_params(\n",
    "    ckpt_dir=pathlib.Path('../pretrained/3d_cluster/').resolve() / f'3d_cluster_{num_atoms=}_radius_{radius_string}_{num_iterations=}_{batch_size=}_{efa_handle}'\n",
    ")\n",
    "\n",
    "npztrainer = NpzTrainer(\n",
    "    data_dir=data_path,\n",
    "    num_train=1500,\n",
    "    num_valid=500,\n",
    "    num_epochs=5000,\n",
    "    max_num_nodes=int(batch_size * num_atoms + 1),\n",
    "    max_num_edges=int(batch_size * num_atoms * min(num_atoms, 40) + 1),\n",
    "    max_num_graphs=batch_size + 1,\n",
    "    energy_unit=1,\n",
    "    length_unit=1,\n",
    "    save_interval_steps=2000,\n",
    "    use_wandb=False\n",
    ")\n",
    "\n",
    "if use_efa is True:\n",
    "    model = EnergyModel(\n",
    "        num_features=128,\n",
    "        mp_max_degree=1,\n",
    "        num_iterations=num_iterations,\n",
    "        era_use_in_iterations=[0, 1],\n",
    "        era_lebedev_num=50,\n",
    "        era_tensor_integration=False,\n",
    "        era_include_pseudotensors=False,\n",
    "        era_max_degree=0,\n",
    "        era_qk_num_features=16,\n",
    "        era_v_num_features=32,\n",
    "        era_max_frequency=jnp.pi,\n",
    "        era_max_length=15,\n",
    "        era_activation_fn=e3x.nn.gelu,\n",
    "    )\n",
    "else:\n",
    "    model = EnergyModel(\n",
    "        num_features=128,\n",
    "        mp_max_degree=1,\n",
    "        num_iterations=num_iterations,\n",
    "        era_use_in_iterations=None\n",
    "        )\n",
    "\n",
    "metrics = npztrainer.run_testing(\n",
    "    params=params, \n",
    "    model=model, \n",
    "    num_test=500, \n",
    "    collect_predictions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df3296a-464f-4119-8431-90f6c87fd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{efa_handle} and {num_iterations=}')\n",
    "print(f'Forces RMSE: {metrics[0]['forces_rmse']}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "euclidean_fast_attention",
   "language": "python",
   "name": "euclidean_fast_attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
